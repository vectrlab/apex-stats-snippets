{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vectrlab/apex-stats-snippets/blob/main/snippet_library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPFYkYNtf6i2"
      },
      "source": [
        "# APEX STATS Code Snippets\n",
        "\n",
        "Licensed under CC BY-NC-SA\n",
        "\n",
        "Release 1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8zZNFBXp5Rc"
      },
      "source": [
        "# Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5E0Lh7xfyqd"
      },
      "outputs": [],
      "source": [
        "#@title Setup Blank Data\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Create a blank DataFrame\n",
        "data = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq6DZMQtrt4y"
      },
      "outputs": [],
      "source": [
        "#@title Setup Example Data: Health Nutrition\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: Health Nutrition\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/healthnutritionandpopulation/example.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEKbZI31HaRh"
      },
      "outputs": [],
      "source": [
        "#@title Setup Example Data: Red Wine Quality\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: Red Wine Quality\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/red-wine-quality/example.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNx7z--7H2mc"
      },
      "outputs": [],
      "source": [
        "#@title Setup Example Data: Connecticut Housing\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: Connecticut Housing\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/connecticut-housing/example.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6__W_Co9rKAZ"
      },
      "outputs": [],
      "source": [
        "#@title Setup Example Data: FIFA19\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: FIFA19\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/fifa19/example.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Example Data: IMDB\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: IMDB\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/movies/movie_metadata.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "GlyK1-FV1v-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Example Data: Salary\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: Salary\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/salary/example.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "yM3c-GWKYHy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Example Data: Cars\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: Cars\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/cars/example.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "upiWhsV_RHPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCiMv8VJdGV_"
      },
      "outputs": [],
      "source": [
        "#@title Setup Example Data: Class Survey\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: Class Survey\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/refs/heads/main/class_survey/example.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Example Data with Error Handling\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Read data file: Your Data URL\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/dataset_name.csv')\n",
        "\n",
        "# Handle errors\n",
        "try:\n",
        "    data\n",
        "    print('The data were loaded.')\n",
        "except NameError:\n",
        "    print('There was a problem loading the data.')"
      ],
      "metadata": {
        "id": "f611erWRokHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Example Data with an Assigned File Path\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Assign filepath: Your Data URL\n",
        "filepath = 'https://raw.githubusercontent.com/vectrlab/apex-stats-datasets/main/dataset_name.csv'\n",
        "\n",
        "# Read data file\n",
        "data = pd.read_csv(filepath)\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "qNMHnpYdVsd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Your Own Data: GitHub Method\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# From GitHub CSV, click 'Raw', copy address bar URL\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/your_repo/datasets/dataset_name.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "WCgOvuHxzYQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Your Own Data: Google Drive Method\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Edit Drive file location folder(s) and file name\n",
        "data = pd.read_csv('/content/drive/My Drive/edit_folder/edit_dataset_name.csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "sesAt9lm1UqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Your Own Data: Google Sheets Method\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Set access to 'Anyone with the link', copy link, and replace\n",
        "# edit?usp=sharing with export?format=csv at the end of the link.\n",
        "data = pd.read_csv('https://docs.google.com/spreadsheets/xxx/export?format=csv')\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "4gpMLTss22GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Assigning Values to Variables\n",
        "\n",
        "# Integer value\n",
        "whole_num = 5\n",
        "\n",
        "# Float-point value\n",
        "decimal = 5.5"
      ],
      "metadata": {
        "id": "olOzLPTJ2Lsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Assigning Column Data to Variables\n",
        "\n",
        "# Assign data['x'] variable\n",
        "var_name1 = data['x']\n",
        "\n",
        "# Assign data['y'] variable\n",
        "var_name2 = data['y']"
      ],
      "metadata": {
        "id": "5QstFATTZqLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Assigning Multi-Line String Data to Variables\n",
        "\n",
        "# Example data: Declaration of Independence\n",
        "doi = \"\"\"\n",
        "When in the Course of human events, it becomes necessary for one people\n",
        "to dissolve the political bands which have connected them with another,\n",
        "and to assume, among the Powers of the earth, the separate and equal\n",
        "station to which the Laws of Nature and of Nature's God entitle them, a\n",
        "decent respect to the opinions of mankind requires that they should\n",
        "declare the causes which impel them to the separation.\n",
        "\n",
        "We hold these truths to be self-evident, that all men are created\n",
        "equal, that they are endowed by their Creator with certain unalienable\n",
        "Rights, that among these are Life, Liberty, and the pursuit of\n",
        "Happiness. That to secure these rights, Governments are instituted\n",
        "among Men, deriving their just powers from the consent of the governed,\n",
        "That whenever any Form of Government becomes destructive of these ends,\n",
        "it is the Right of the People to alter or to abolish it, and to\n",
        "institute new Government, laying its foundation on such principles and\n",
        "organizing its powers in such form, as to them shall seem most likely\n",
        "to effect their Safety and Happiness.  Prudence, indeed, will dictate\n",
        "that Governments long established should not be changed for light and\n",
        "transient causes; and accordingly all experience hath shown, that\n",
        "mankind are more disposed to suffer, while evils are sufferable, than\n",
        "to right themselves by abolishing the forms to which they are\n",
        "accustomed.  But when a long train of abuses and usurpations, pursuing\n",
        "invariably the same Object evinces a design to reduce them under\n",
        "absolute Despotism, it is their right, it is their duty, to throw off\n",
        "such Government, and to provide new Guards for their future security.\n",
        "--Such has been the patient sufferance of these Colonies; and such is\n",
        "now the necessity which constrains them to alter their former Systems\n",
        "of Government. The history of the present King of Great Britain is a\n",
        "history of repeated injuries and usurpations, all having in direct\n",
        "object the establishment of an absolute Tyranny over these States.  To\n",
        "prove this, let Facts be submitted to a candid world.\n",
        "\n",
        "He has refused his Assent to Laws, the most wholesome and necessary for\n",
        "the public good.\n",
        "\n",
        "He has forbidden his Governors to pass Laws of immediate and pressing\n",
        "importance, unless suspended in their operation till his Assent should\n",
        "be obtained; and when so suspended, he has utterly neglected to attend\n",
        "to them.\n",
        "\n",
        "He has refused to pass other Laws for the accommodation of large\n",
        "districts of people, unless those people would relinquish the right of\n",
        "Representation in the Legislature, a right inestimable to them and\n",
        "formidable to tyrants only.\n",
        "\n",
        "He has called together legislative bodies at places unusual,\n",
        "uncomfortable, and distant from the depository of their Public Records,\n",
        "for the sole purpose of fatiguing them into compliance with his\n",
        "measures.\n",
        "\n",
        "He has dissolved Representative Houses repeatedly, for opposing with\n",
        "manly firmness his invasions on the rights of the people.\n",
        "\n",
        "He has refused for a long time, after such dissolutions, to cause\n",
        "others to be elected; whereby the Legislative Powers, incapable of\n",
        "Annihilation, have returned to the People at large for their exercise;\n",
        "the State remaining in the mean time exposed to all the dangers of\n",
        "invasion from without, and convulsions within.\n",
        "\n",
        "He has endeavoured to prevent the population of these States; for that\n",
        "purpose obstructing the Laws of Naturalization of Foreigners; refusing\n",
        "to pass others to encourage their migration hither, and raising the\n",
        "conditions of new Appropriations of Lands.\n",
        "\n",
        "He has obstructed the Administration of Justice, by refusing his Assent\n",
        "to Laws for establishing Judiciary Powers.\n",
        "\n",
        "He has made judges dependent on his Will alone, for the tenure of their\n",
        "offices, and the amount and payment of their salaries.\n",
        "\n",
        "He has erected a multitude of New Offices, and sent hither swarms of\n",
        "Officers to harass our People, and eat out their substance.\n",
        "\n",
        "He has kept among us, in times of peace, Standing Armies without the\n",
        "Consent of our legislatures.\n",
        "\n",
        "He has affected to render the Military independent of and superior to\n",
        "the Civil Power.\n",
        "\n",
        "He has combined with others to subject us to a jurisdiction foreign to\n",
        "our constitution, and unacknowledged by our laws; giving his Assent to\n",
        "their Acts of pretended legislation:\n",
        "\n",
        "For quartering large bodies of armed troops among us:\n",
        "\n",
        "For protecting them, by a mock Trial, from Punishment for any Murders\n",
        "which they should commit on the Inhabitants of these States:\n",
        "\n",
        "For cutting off our Trade with all parts of the world:\n",
        "\n",
        "For imposing taxes on us without our Consent:\n",
        "\n",
        "For depriving us, in many cases, of the benefits of Trial by Jury:\n",
        "\n",
        "For transporting us beyond Seas to be tried for pretended offences:\n",
        "\n",
        "For abolishing the free System of English Laws in a neighbouring\n",
        "Province, establishing therein an Arbitrary government, and enlarging\n",
        "its Boundaries so as to render it at once an example and fit instrument\n",
        "for introducing the same absolute rule into these Colonies:\n",
        "\n",
        "For taking away our Charters, abolishing our most valuable Laws, and\n",
        "altering fundamentally the Forms of our Governments:\n",
        "\n",
        "For suspending our own Legislatures, and declaring themselves invested\n",
        "with Power to legislate for us in all cases whatsoever.\n",
        "\n",
        "He has abdicated Government here, by declaring us out of his Protection\n",
        "and waging War against us.\n",
        "\n",
        "He has plundered our seas, ravaged our Coasts, burnt our towns, and\n",
        "destroyed the lives of our people.\n",
        "\n",
        "He is at this time transporting large armies of foreign mercenaries to\n",
        "compleat the works of death, desolation and tyranny, already begun with\n",
        "circumstances of Cruelty & perfidy scarcely paralleled in the most\n",
        "barbarous ages, and totally unworthy of the Head of a civilized nation.\n",
        "\n",
        "He has constrained our fellow Citizens taken Captive on the high Seas\n",
        "to bear Arms against their Country, to become the executioners of their\n",
        "friends and Brethren, or to fall themselves by their Hands.\n",
        "\n",
        "He has excited domestic insurrections amongst us, and has endeavoured\n",
        "to bring on the inhabitants of our frontiers, the merciless Indian\n",
        "Savages, whose known rule of warfare, is an undistinguished destruction\n",
        "of all ages, sexes and conditions.\n",
        "\n",
        "In every stage of these Oppressions We have Petitioned for Redress in\n",
        "the most humble terms:  Our repeated Petitions have been answered only\n",
        "by repeated injury.  A Prince, whose character is thus marked by every\n",
        "act which may define a Tyrant, is unfit to be the ruler of a free\n",
        "People.\n",
        "\n",
        "Nor have We been wanting in attention to our British brethren. We have\n",
        "warned them from time to time of attempts by their legislature to\n",
        "extend an unwarrantable jurisdiction over us. We have reminded them of\n",
        "the circumstances of our emigration and settlement here.  We have\n",
        "appealed to their native justice and magnanimity, and we have conjured\n",
        "them by the ties of our common kindred to disavow these usurpations,\n",
        "which would inevitably interrupt our connections and correspondence.\n",
        "They too have been deaf to the voice of justice and of consanguinity.\n",
        "We must, therefore, acquiesce in the necessity, which denounces our\n",
        "Separation, and hold them, as we hold the rest of mankind, Enemies in\n",
        "War, in Peace Friends.\n",
        "\n",
        "We, therefore, the Representatives of the United States of America, in\n",
        "General Congress, Assembled, appealing to the Supreme Judge of the\n",
        "world for the rectitude of our intentions, do, in the Name, and by the\n",
        "Authority of the good People of these Colonies, solemnly publish and\n",
        "declare, That these United Colonies are, and of Right ought to be Free\n",
        "and Independent States; that they are Absolved from all Allegiance to\n",
        "the British Crown, and that all political connection between them and\n",
        "the State of Great Britain, is and ought to be totally dissolved; and\n",
        "that as Free and Independent States, they have full Power to levy War,\n",
        "conclude Peace, contract Alliances, establish Commerce, and to do all\n",
        "other Acts and Things which Independent States may of right do.  And\n",
        "for the support of this Declaration, with a firm reliance on the\n",
        "Protection of Divine Providence, we mutually pledge to each other our\n",
        "Lives, our Fortunes and our sacred Honor.\n",
        "\"\"\"\n",
        "print(doi)"
      ],
      "metadata": {
        "id": "iE_sA9AxKJYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Renaming Columns (Variables)\n",
        "\n",
        "# Rename dataframe columns\n",
        "data.columns = ['var_name1', 'var_name2', 'var_name3']\n",
        "\n",
        "# Preview data\n",
        "data"
      ],
      "metadata": {
        "id": "WxFsToXbSLLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select Columns (Variables)\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Select columns\n",
        "data = data[['x1', 'x2']]\n",
        "\n",
        "# Preview new dataframe\n",
        "data"
      ],
      "metadata": {
        "id": "zlbnj3RuS4Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select Rows (Cases)\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Select rows\n",
        "data = data[data['x1'].isin(['case1', 'case2'])]\n",
        "\n",
        "# Preview new dataframe\n",
        "data"
      ],
      "metadata": {
        "id": "87HGZLGFVajy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8akdLlv0_UG-"
      },
      "outputs": [],
      "source": [
        "# @title Sorting a DataFrame by a Column\n",
        "\n",
        "# Sort by column 'y' in ascending order (without modifying the DataFrame)\n",
        "data.sort_values(by=['y'], ascending=True)\n",
        "\n",
        "# To make the sorting permanent (i.e., an 'in-place' sort),\n",
        "# reassign the result to the same variable:\n",
        "# data = data.sort_values(by=['y'], ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Filtering a DataFrame\n",
        "\n",
        "# Subset data: one condition\n",
        "# > greater than, >= great than or equal to\n",
        "# > less than, <= less than or equal to\n",
        "# == equal to, != not equal to\n",
        "subset = data[data['x'] > 10]\n",
        "\n",
        "# Subset data: negating a condition\n",
        "# ~ not\n",
        "subset2 = data[~(data['x'] > 10)]\n",
        "\n",
        "# Subset data: two conditions\n",
        "# & and, | or\n",
        "subset3 = data[(data['x'] > 5) & (data['y'] < 10)]\n",
        "subset4 = data[(data['x'] > 5) | (data['y'] < 10)]"
      ],
      "metadata": {
        "id": "Nzf7cMMn45Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU0y6TSoroxU"
      },
      "source": [
        "# Population vs Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLjVS1oary8O"
      },
      "outputs": [],
      "source": [
        "#@title Generate a Population Distribution\n",
        "\n",
        "# Import libraries\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Set the seed so that everyone has the same values, or\n",
        "# comment out the line below to generate a unique population each time.\n",
        "random.seed(21715)\n",
        "\n",
        "# Set population size\n",
        "n = 1000\n",
        "\n",
        "# Specify maximum value\n",
        "max_value = 100.0\n",
        "\n",
        "# Generate a uniform distribution with N values,\n",
        "# from 0 to the maximum value, chosen at random.\n",
        "population = [random.random() * max_value for x in range(n)]\n",
        "\n",
        "# Add the population distribution to the DataFrame\n",
        "data = data.assign(x=population)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vUbjCtXsCtb"
      },
      "outputs": [],
      "source": [
        "#@title Population or Sample Size\n",
        "\n",
        "# Population or sample size\n",
        "len(data['x'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWhqp_IRsGOt"
      },
      "outputs": [],
      "source": [
        "#@title Population or Sample Mean\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Mean\n",
        "np.mean(data['x'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9fBQgwlsKtq"
      },
      "outputs": [],
      "source": [
        "#@title Population Standard Deviation\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Population standard deviation\n",
        "np.std(data['x'], ddof=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwMB3YBDsOps"
      },
      "outputs": [],
      "source": [
        "#@title Sample Standard Deviation\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the sample standard deviation;\n",
        "# ddof is delta degrees of freedom and\n",
        "# N - ddof is used in the variance calculation.\n",
        "np.std(data['x'], ddof=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajq0VRHts3lh"
      },
      "outputs": [],
      "source": [
        "#@title Generate a Random Sample\n",
        "\n",
        "# Import libraries\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Sample size\n",
        "n = 5\n",
        "\n",
        "# Generate a single sample\n",
        "one_sample = np.random.choice(data['x'], n)\n",
        "\n",
        "# Display sample data\n",
        "one_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLpNZJIys_4w"
      },
      "outputs": [],
      "source": [
        "#@title Generate a Sampling Distribution\n",
        "\n",
        "# Import libraries\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Specify number of samples in the sampling distribution\n",
        "num_samples = 2000\n",
        "\n",
        "# Sample size\n",
        "n = 5\n",
        "\n",
        "# Define a function\n",
        "def drange():\n",
        "    # Pick a random starting spot in the distribution\n",
        "    x = random.randrange(0, len(data['x']) - (n + 1))\n",
        "    # Select n values starting from that spot -\n",
        "    # Dave note: We may need to fix this, as the selection\n",
        "    # will be biased if data are in a nonrandom order\n",
        "    return slice(x, x + n)\n",
        "\n",
        "# Assemble the sampling distribution by finding means of repeated samples\n",
        "sampling_dist = [np.mean(data['x'][drange()]) for x in range(num_samples)]\n",
        "\n",
        "# Display the sampling distribution\n",
        "sampling_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdjSMjNMtMBw"
      },
      "outputs": [],
      "source": [
        "#@title Calculate Standard Error\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Sample size\n",
        "n = 5\n",
        "\n",
        "# Standard error\n",
        "se = np.std(data['x'], ddof=1) / np.sqrt(n)\n",
        "\n",
        "# Display result\n",
        "se"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJxCKOLbq99A"
      },
      "source": [
        "# Confidence Interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtiSRk5jtQBY"
      },
      "outputs": [],
      "source": [
        "#@title Calculate 95% Confidence Interval (Extended Version)\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample size\n",
        "n = 5\n",
        "\n",
        "# Standard error\n",
        "se = np.std(data['x'], ddof=1) / np.sqrt(n)\n",
        "\n",
        "# Area of one tail outside the confidence interval\n",
        "tail = 1 - (1 - .95) / 2\n",
        "\n",
        "# Z-score corresponding to 97.5% area below it\n",
        "z = norm.ppf(tail)\n",
        "\n",
        "# Find and save lower and upper bounds\n",
        "lower_bound = np.mean(data['x']) - z * se\n",
        "upper_bound = np.mean(data['x']) + z * se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZluEoGuBtTkt"
      },
      "outputs": [],
      "source": [
        "#@title Calculate 95% Confidence Interval (Simple Version)\n",
        "\n",
        "# Import libraries\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "# Calculate mean\n",
        "mu = np.mean(data['x'])\n",
        "\n",
        "# Calculate standard deviation\n",
        "sigma = np.std(data['x'], ddof=1)\n",
        "\n",
        "# Specify confidence level\n",
        "conf_level = 0.95\n",
        "\n",
        "# Find confidence interval\n",
        "stats.norm.interval(conf_level, loc=mu, scale=sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hoPp0dKrB-k"
      },
      "source": [
        "# *Z*-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuVEHacLuCwx"
      },
      "outputs": [],
      "source": [
        "#@title Generate *z*-Scores\n",
        "\n",
        "# Import library\n",
        "from scipy import stats\n",
        "\n",
        "# Create a new data column 'z' containing z-scores\n",
        "data['z'] = stats.zscore(data['x'])\n",
        "\n",
        "# Display data column\n",
        "data['z']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKsMjv14_kWy"
      },
      "outputs": [],
      "source": [
        "#@title Apply *z*-Score Formula to User Inputs\n",
        "\n",
        "# Ask user to insert a new score\n",
        "raw = float(input('Score = '))\n",
        "\n",
        "# Ask user to insert a mean\n",
        "mean = float(input('Mean = '))\n",
        "\n",
        "# Ask the user to insert standard deviation\n",
        "sd = float(input('Input the standard deviation: '))\n",
        "\n",
        "# Find z-score with formula, round to 2 decimal places\n",
        "z = round((raw - mean) / sd, 2)\n",
        "\n",
        "# Print result\n",
        "print('z = ', z)\n",
        "\n",
        "# Note:\n",
        "# The z-score formula is: z = (raw score - mean) / sd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_Ee5_0d6LOi"
      },
      "outputs": [],
      "source": [
        "#@title Generate Raw Scores\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Creat empty list for raw scores\n",
        "raw_scores = []\n",
        "\n",
        "# Find population standard deviation\n",
        "sd = np.std(data['x'])\n",
        "\n",
        "# Find mean from data column x\n",
        "mean = data['x'].mean()\n",
        "\n",
        "# Access each z-score\n",
        "for z in data['z']:\n",
        "    # Save each raw score, calculated using formula, into list\n",
        "    raw_scores.append(z * sd + mean)\n",
        "\n",
        "# Display result\n",
        "raw_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvTkRGKpp_Ix"
      },
      "outputs": [],
      "source": [
        "#@title Apply Raw Score Formula to User Inputs\n",
        "\n",
        "# Input new score\n",
        "z = float(input('z = '))\n",
        "\n",
        "# Input mean\n",
        "mean = float(input('Mean: '))\n",
        "\n",
        "# Input standard deviation\n",
        "sd = float(input('Input the standard deviation: '))\n",
        "\n",
        "# Find score using formula, round to 2 decimal places\n",
        "raw = round(z * sd + mean, 2)\n",
        "\n",
        "# Print result\n",
        "print('Score = ', raw)\n",
        "\n",
        "# Note:\n",
        "# The raw score formula is: raw score = z-score * sd + mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9pokptrJrj"
      },
      "source": [
        "# CDF and Inverse CDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg-z8VlGYlTF"
      },
      "outputs": [],
      "source": [
        "#@title Cumulative Distribution Function\n",
        "\n",
        "# Import function\n",
        "from scipy.stats import norm\n",
        "\n",
        "# CDF of a standard normal distribution\n",
        "norm.cdf(1.45, loc=0, scale=1)\n",
        "\n",
        "# Note:\n",
        "# When we specify 1.45, we are interested in the area\n",
        "# under the curve to the left of the point 1.45,\n",
        "# loc is where you specify your mean, and\n",
        "# scale is where you specify your standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laQTYD6ZsqfG"
      },
      "outputs": [],
      "source": [
        "#@title Area Under the Curve\n",
        "\n",
        "# Import function\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Input mean\n",
        "mean = float(input('Specify your mean: '))\n",
        "\n",
        "# Input standard deviation\n",
        "stdev = float(input('Specify your standard deviation: '))\n",
        "\n",
        "# Input lower bound\n",
        "lower_bound = float(input('Specify your lower bound: '))\n",
        "\n",
        "# Input upper bound\n",
        "upper_bound = float(input('Specify your upper bound: '))\n",
        "\n",
        "# Calculate area under the curve between the bounds\n",
        "larger_area = norm.cdf(upper_bound, loc=mean, scale=stdev)\n",
        "smaller_area = norm.cdf(lower_bound, loc=mean, scale=stdev)\n",
        "area_under_curve = larger_area - smaller_area\n",
        "\n",
        "# Print result and round to two decimal places\n",
        "print(\n",
        "    f\"\"\"\n",
        "    The area under the curve from {lower_bound} to {upper_bound}\n",
        "    is {round(area_under_curve, 2)}.\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "# Note:\n",
        "# The area under the curve is calculated here by subtracting the\n",
        "# smaller cumulative area (smaller_area) from the larger (larger_area)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2_ctPDicVOg"
      },
      "outputs": [],
      "source": [
        "#@title Inverse Cumulative Distribution Function\n",
        "\n",
        "# Import function\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Input mean\n",
        "mean = float(input('Specify your mean: '))\n",
        "\n",
        "# Input standard deviation\n",
        "stdev = float(input('Specify your standard deviation: '))\n",
        "\n",
        "# Input5 percentile\n",
        "percentile = float(input('Specify the percentile (from 0-1 range): '))\n",
        "\n",
        "# Find inverse norm result with norm.ppf method\n",
        "inv_norm_ans = norm.ppf(percentile, loc=mean, scale=stdev)\n",
        "\n",
        "# Print result and round answer to two decimal places\n",
        "print(\n",
        "    f\"\"\"\n",
        "    With a mean {mean} and standard deviation of {stdev},\n",
        "    the {int(percentile*100)}th percentile is {round(inv_norm_ans, 2)}.\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "# Notes:\n",
        "# norm.ppf returns a *percentile* confidence interval for a one-tailed test.\n",
        "# For example, when we specify 0.95, we indicated the area under the curve\n",
        "# to be 0.95 with loc to be our mean and scale to be our standard deviation.\n",
        "# In R, it is qnorm(0.95, 0, 1) or qnorm(0.05,0,1,lower.tail=FALSE)\n",
        "# with mean 0 and standard deviation 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGhqgx8QrTXf"
      },
      "source": [
        "# Understanding Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check Variable Levels\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Display variable levels\n",
        "print(data['x'].unique())"
      ],
      "metadata": {
        "id": "5KJu-B2SSn0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWj3BOmJfBak"
      },
      "outputs": [],
      "source": [
        "#@title Sampling Cases from DataFrame\n",
        "\n",
        "# Random sampling\n",
        "new_data = data.sample(n=10, random_state=1)\n",
        "\n",
        "# Display sample\n",
        "new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJyUX9wMnwwp"
      },
      "outputs": [],
      "source": [
        "#@title Find Missing Values in DataFrame Columns\n",
        "\n",
        "# Display status of each cell ('True' indicates missing data)\n",
        "data['x'].isna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBENykuhn8KX"
      },
      "outputs": [],
      "source": [
        "#@title Find Missing Values in a DataFrame\n",
        "\n",
        "# Display status of each cell ('True' indicates missing data)\n",
        "data.isna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjpQvk9Ro8kt"
      },
      "outputs": [],
      "source": [
        "#@title Find Rows Where NaN Exists\n",
        "\n",
        "# Display cases with NaN values\n",
        "data['x'][data['x'].isna() == True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruTFx52s_CmF"
      },
      "outputs": [],
      "source": [
        "# @title Identify Missing Values in a DataFrame\n",
        "\n",
        "# Find missing values and create a boolean Series\n",
        "bool_series = pd.isnull(data['x'])\n",
        "\n",
        "# Preview boolen Series ('True' indicates a missing value)\n",
        "print(bool_series.head())\n",
        "\n",
        "# Display rows with missing values (blank output means no missing values)\n",
        "data[bool_series]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEwt3Aoop-4l"
      },
      "outputs": [],
      "source": [
        "#@title Discover Data Types\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create dataframe with 'x' variable (integer data type)\n",
        "data = pd.DataFrame(np.random.randint(0, 2, size=10), columns=['x'])\n",
        "\n",
        "# Diplay data types (data are 0s and 1s)\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YiXQmQvsHrd"
      },
      "outputs": [],
      "source": [
        "#@title Convert Data Type into Category\n",
        "\n",
        "# Convert integers into categories (factors in R)\n",
        "data['x'] = data['x'].astype('category')\n",
        "\n",
        "# Diplay data types\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boa7wiHHojJV"
      },
      "outputs": [],
      "source": [
        "#@title Convert Data Type and Insert a New Column into a DataFrame\n",
        "\n",
        "# Convert integers into categories (factors in R)\n",
        "data['x6'] = data['x'].astype('category')\n",
        "\n",
        "# Diplay data types\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Galton Board (Bean Machine) Simulation\n",
        "\n",
        "# Import library\n",
        "import random\n",
        "\n",
        "# Set constants (number of beans and slots)\n",
        "num_beans = 2000\n",
        "num_slots = 28\n",
        "\n",
        "# Define bean machine function\n",
        "def bean_machine(num_beans, num_slots):\n",
        "    \"\"\"\n",
        "    Simulates a bean machine (aka Galton board)\n",
        "    and returns the distribution of beans in each slot.\n",
        "    \"\"\"\n",
        "    slots = [0] * (num_slots + 1)\n",
        "    for i in range(num_beans):\n",
        "        pos = num_slots // 2\n",
        "        for j in range(num_slots - 1):\n",
        "            if random.random() < 0.5:\n",
        "                pos -= 1\n",
        "            else:\n",
        "                pos += 1\n",
        "                if pos > num_slots:\n",
        "                    pos = num_slots - 1\n",
        "        slots[pos] += 1\n",
        "    return slots\n",
        "\n",
        "# Call bean machine function\n",
        "beans = bean_machine(num_beans, num_slots)\n",
        "\n",
        "# Print distribution results\n",
        "print(beans)\n",
        "\n",
        "## Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define plotting function\n",
        "def plot_counts(counts):\n",
        "    \"\"\"\n",
        "    Plots bean counts in each bin.\n",
        "    \"\"\"\n",
        "    # Create figure and axis object\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Convert counts array to numpy array\n",
        "    if isinstance(counts[0], (list, tuple)):\n",
        "        counts = np.array(counts)\n",
        "\n",
        "    # Plot height of each count using bar plot\n",
        "    ax.bar(range(len(counts)), height=counts, width=1)\n",
        "\n",
        "    # Set x-axis labels and title\n",
        "    ax.set_xlabel('Bin')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.set_title('Bean Machine/Quincunx')\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "\n",
        "# Call plotting function\n",
        "plot_counts(beans)"
      ],
      "metadata": {
        "id": "8vEwEF6UN2cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bean Machine Simulation Animation\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Set constants (number of beans and slots)\n",
        "num_slots = 28\n",
        "num_beans = 200\n",
        "\n",
        "# Initialize slots to collect balls\n",
        "slots = [0] * (num_slots + 1)\n",
        "\n",
        "# Create figure and axis for plotting\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Define animation function\n",
        "def update(frame):\n",
        "    \"\"\"\n",
        "    Simulates path of a bean through random left or right steps,\n",
        "    updates final slot position, and redraws bar chart.\n",
        "    \"\"\"\n",
        "    ax.cla()  # Clear previous frame\n",
        "\n",
        "    pos = num_slots // 2\n",
        "    for j in range(num_slots - 1):\n",
        "        direction = np.random.choice([-1, 1])\n",
        "        pos += direction\n",
        "        if pos > num_slots:\n",
        "            pos = num_slots - 1\n",
        "    slots[pos] += 1\n",
        "\n",
        "    ax.bar(range(0, num_slots + 1), slots, alpha=0.7, edgecolor='black')\n",
        "    ax.set_xlim(-1, num_slots + 1)\n",
        "    ax.set_ylim(0, num_beans)\n",
        "    ax.set_xlabel('Bin')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.set_title(f'Bean Machine/Quincunx (Frame {frame + 1})')\n",
        "\n",
        "# Create animation subtracting 1 to correct first frame\n",
        "anim = FuncAnimation(fig, update, frames=(num_beans - 1), repeat=False)\n",
        "\n",
        "# Display animation as HTML video\n",
        "html_video = anim.to_jshtml()\n",
        "\n",
        "# Show animation\n",
        "HTML(html_video)"
      ],
      "metadata": {
        "id": "7niWwkQlOemd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling Techniques"
      ],
      "metadata": {
        "id": "vd2RIJXsg1Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sampling Words in Text (String Data)\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Create array of counts: replace with letter counts\n",
        "counts = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Calculate mean\n",
        "np.mean(counts)"
      ],
      "metadata": {
        "id": "LwtQovEz93RP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simple Random Sampling Words in Text (String Data)\n",
        "\n",
        "# Import libraries\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Define punctuation removal function\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([c for c in text if c not in '.,!?:-'])\n",
        "\n",
        "# Remove punctuation from entire text\n",
        "clean_doi = remove_punctuation(doi)\n",
        "\n",
        "# Sample size of 10\n",
        "n = 10\n",
        "\n",
        "# Generate a single sample\n",
        "one_sample = np.random.choice(clean_doi.split(), n)\n",
        "\n",
        "# Show sample distribution\n",
        "print('The randomly sampled words are: ')\n",
        "print(one_sample)\n",
        "\n",
        "# Count letters in each word\n",
        "for word in one_sample:\n",
        "    print('\\n\"' + word + '\" has ' + str(len(word)) + ' letters')\n",
        "\n",
        "# Create array of counts\n",
        "srs = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Calculate mean\n",
        "np.mean(srs)"
      ],
      "metadata": {
        "id": "GdKZBh_hAn00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Systematic Sampling Words in Text (String Data)\n",
        "\n",
        "# Word count\n",
        "len(doi.split())\n",
        "\n",
        "# Import libraries\n",
        "import random\n",
        "\n",
        "# Set maximum value; replace 1 with word count\n",
        "maximum = 1\n",
        "\n",
        "# Generate a random number\n",
        "random.randrange(maximum + 1)\n",
        "\n",
        "# Import libraries\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Define punctuation removal function\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([c for c in text if c not in '.,!?:-'])\n",
        "\n",
        "# Remove punctuation from entire text\n",
        "clean_doi = remove_punctuation(doi)\n",
        "\n",
        "# Set the randomly generated number as the starting point\n",
        "starting_point = 0\n",
        "words = clean_doi.split()\n",
        "\n",
        "# Choose every 30th word\n",
        "index = (starting_point % len(words)) if starting_point else 0\n",
        "selected_words = []\n",
        "\n",
        "while len(selected_words) < 10:\n",
        "    selected_words.append(words[index])\n",
        "    index += 30\n",
        "    index %= len(words)\n",
        "\n",
        "# Show sample distribution\n",
        "print('The randomly sampled words are: ')\n",
        "print(selected_words)\n",
        "\n",
        "# Count letters in each word\n",
        "for word in selected_words:\n",
        "        print('\\n\"' + word + '\" has ' + str(len(word)) + ' letters')\n",
        "\n",
        "# Create array of counts\n",
        "systematic = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Calculate mean\n",
        "np.mean(systematic)"
      ],
      "metadata": {
        "id": "OeJiGlOYLhc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Gd4eBSq1nU"
      },
      "source": [
        "# Hypothesis Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZBf4XOuN17e"
      },
      "outputs": [],
      "source": [
        "#@title One Sample *t*-test\n",
        "\n",
        "# Import library\n",
        "from scipy import stats\n",
        "\n",
        "# One sample t-test (arg1: sample observation, arg2: expected H0 value)\n",
        "result = stats.ttest_1samp(data['x'], 39)\n",
        "\n",
        "# To extract details from result:\n",
        "# result.statistic\n",
        "# result.pvalue\n",
        "# results.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQr_in7EQt-A"
      },
      "outputs": [],
      "source": [
        "#@title Independent Samples *t*-Test using `scipy`\n",
        "\n",
        "# Import library\n",
        "from scipy import stats\n",
        "\n",
        "# Independent samples t-test (arg1: sample 1, arg2: sample 2)\n",
        "result = stats.ttest_ind(data['x'], data['x1'])\n",
        "\n",
        "# To extract details from result:\n",
        "# result.statistic\n",
        "# result.pvalue\n",
        "# results.df\n",
        "\n",
        "# Additional arguments:\n",
        "# axis= operate along rows (0) or columns (1)\n",
        "# equal_var= group population variances equal (True) or unequal (False)\n",
        "# nan_policy= return NaN ('propagate'), remove ('omit'), ValueError 'raise'\n",
        "# permutations= number of permutations (permutation resampling)\n",
        "# random_state= seed for random number generation (permutation resampling)\n",
        "# alternative= two-tailed ('two-sided'), one-tailed ('greater')('less')\n",
        "# trim= percentage of data to trim to deal with outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i30XgfosVgUY"
      },
      "outputs": [],
      "source": [
        "#@title Paired Samples *t*-test\n",
        "\n",
        "# Import library\n",
        "from scipy import stats\n",
        "\n",
        "# Paired samples t-test (arg1: sample 1, arg2: sample 2)\n",
        "result = stats.ttest_rel(data['x'], data['x1'])\n",
        "\n",
        "# To extract details from result:\n",
        "# result.statistic\n",
        "# result.pvalue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5b4_xE-bzWb"
      },
      "outputs": [],
      "source": [
        "#@title Correlation Analysis\n",
        "\n",
        "# Import library\n",
        "from scipy import stats\n",
        "\n",
        "# Pearson's R (returns a tuple)\n",
        "corr_test = stats.pearsonr(data['x'], data['x1'])\n",
        "\n",
        "# r: Pearson's correlation efficient\n",
        "print(corr_test[0])\n",
        "\n",
        "# p-value: two-tailed p-val\n",
        "print(corr_test[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCeHiTsEHm-C"
      },
      "outputs": [],
      "source": [
        "#@title Simple Linear Regression\n",
        "\n",
        "# Import library\n",
        "from scipy import stats\n",
        "\n",
        "# Simple regression\n",
        "result = stats.linregress(data['x'], data['x1'])\n",
        "\n",
        "# To extract details from result:\n",
        "# result.slope\n",
        "# result.intercept\n",
        "# result.rvalue\n",
        "# result.pvalue\n",
        "# result.stderr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simple Linear Regression with Regression Statistics\n",
        "\n",
        "# Calculate regression statistics and assign to variable names\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
        "    data['x'], data['x1']\n",
        "    )\n",
        "\n",
        "# Print regression stats\n",
        "print(\n",
        "    f\"\"\"Results:\n",
        "    slope = {slope}\n",
        "    y-intercept = {intercept}\n",
        "    r = {r_value}\n",
        "    p = {p_value}\n",
        "    se = {std_err}\n",
        "    \"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "9ISpWxDtbdG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E43QwcpUqmXk"
      },
      "outputs": [],
      "source": [
        "#@title One-Way Chi-Square Test\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# One-way Chi-square\n",
        "var_name = data['x']\n",
        "\n",
        "# Calculate total observations\n",
        "n = len(\n",
        "    [value for value in var_name\n",
        "     if value == 'category1' or value == 'category2']\n",
        "    )\n",
        "\n",
        "# Calculate expected frequencies based on the proportions\n",
        "expected_freqs = [n // 2, n // 2]\n",
        "print(\n",
        "    f\"\"\"Expected frequencies based on sample size (n = {n}):\n",
        "    Category1 {expected_freqs[0]}\n",
        "    Category2 {expected_freqs[1]}\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "# Calculate observed frequencies\n",
        "observed_freqs = var_name.value_counts()\n",
        "print(\n",
        "    f\"\"\"Observed frequencies:\n",
        "    Category1 {observed_freqs.iloc[0]}\n",
        "    Category2 {observed_freqs.iloc[1]}\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "# Perform chi-square test\n",
        "result = stats.chisquare(observed_freqs, expected_freqs)\n",
        "\n",
        "# Print result\n",
        "print(\n",
        "    f\"\"\"Chi-Square test result:\n",
        "    2 = {result[0]}\n",
        "    p-value = {result[1]}\n",
        "    \"\"\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Two-Way Chi-Square Test\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Create frequency table (contingency table)\n",
        "observed = pd.crosstab(\n",
        "    data['x1'], data['x2'],\n",
        "    rownames=[None], colnames=[None]\n",
        "    )\n",
        "\n",
        "# Print observed frequencies\n",
        "print(\n",
        "    f\"\"\"Observed Frequencies:\n",
        "    \\n{observed}\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "# Import library\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Chi-square test of independence\n",
        "result = chi2_contingency(observed)\n",
        "\n",
        "# Print expected frequencies table\n",
        "rows = ['category1', 'category2']\n",
        "columns = ['category1', 'category2', 'category3']\n",
        "print(\n",
        "    f\"\"\"Expected Frequencies:\n",
        "    \\n{pd.DataFrame(result.expected_freq, index=rows, columns=columns)}\n",
        "    \"\"\")\n",
        "\n",
        "# Print results\n",
        "print(\n",
        "    f\"\"\"Chi-Square test result:\n",
        "    2 = {result.statistic}\n",
        "    p-value = {result.pvalue}\n",
        "    Degrees of freedom = {result.dof}\n",
        "    \"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "wVy4BaI9vtgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlqtWZt8rBSI"
      },
      "outputs": [],
      "source": [
        "#@title One-Way ANOVA using `scipy`\n",
        "\n",
        "# Import library\n",
        "from scipy import stats\n",
        "\n",
        "# One-way ANOVA\n",
        "result = stats.f_oneway(data['x'], data['x1'])\n",
        "\n",
        "# Print statistic and p-value\n",
        "print(result.statistic)\n",
        "print(result.pvalue)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title One-Way ANOVA using `statsmodels`\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Run one-way ANOVA\n",
        "# ols() ordinary least squares\n",
        "# C() categorical IV\n",
        "var_name = ols('y ~ C(x)', data=data).fit()\n",
        "\n",
        "# Print ANOVA table\n",
        "print(sm.stats.anova_lm(var_name, typ=2))"
      ],
      "metadata": {
        "id": "bpC168TSUPY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assumptions Testing"
      ],
      "metadata": {
        "id": "sNhGrMdrTqoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Levene's Test\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Install package\n",
        "try:\n",
        "    import pingouin as pg\n",
        "    print('The pingouin library is already installed.')\n",
        "except ImportError as e:\n",
        "    !pip install pingouin\n",
        "    import pingouin as pg\n",
        "    print('The pingouin library was installed.')\n",
        "\n",
        "# Levene's test for homogeneity of variances\n",
        "test = pg.homoscedasticity(\n",
        "    data, dv='y',\n",
        "    group='x',\n",
        "    method='levene',\n",
        "    alpha=0.05\n",
        "    )\n",
        "\n",
        "# Print result\n",
        "print(test)\n",
        "\n",
        "# Interpret Levene's test\n",
        "if test.pval.iloc[0] < .05:\n",
        "    print(\n",
        "        f\"\"\"\n",
        "        Levene's test was statistically significant\n",
        "        (p = {str(test.pval.iloc[0].round(2))}). The assumption of equality of\n",
        "        variances was violated, meaning that the variability\n",
        "        within each group is not the same.\n",
        "        \"\"\"\n",
        "        )\n",
        "else:\n",
        "    print(\n",
        "        f\"\"\"\n",
        "        Levene's test was not statistically significant\n",
        "        (p = {str(test.pval.iloc[0].round(2))}). The assumption of equality of\n",
        "        variances was met, meaning that the variability\n",
        "        within each group is roughly the same.\n",
        "        \"\"\"\n",
        "        )"
      ],
      "metadata": {
        "id": "9sk6AB-vTajT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-Hoc Testing"
      ],
      "metadata": {
        "id": "3jtevNHjVB1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tukey's HSD\n",
        "\n",
        "# Import libraries\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Tukey's HSD\n",
        "tukey_hsd = pairwise_tukeyhsd(data['y'], data['x'])\n",
        "print(tukey_hsd)"
      ],
      "metadata": {
        "id": "3nne3z9dUyRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pX37YzwPOGM"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuCRVVz8xXEp"
      },
      "outputs": [],
      "source": [
        "#@title Kernel Density Estimate Plot\n",
        "\n",
        "# Import library\n",
        "import seaborn as sns\n",
        "\n",
        "# KDE plot\n",
        "sns.kdeplot(data = data['x'], fill=True, bw_adjust=3, color='green')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VFibOBnXCfx"
      },
      "outputs": [],
      "source": [
        "#@title Dot Plot\n",
        "\n",
        "# Import library\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate dot plot\n",
        "sns.stripplot(x=data['x'], y=data['y'], color='blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2O8CseolCnQ"
      },
      "outputs": [],
      "source": [
        "#@title Box Plot (No Parameter Adjustment)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Figure size\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Generate box plot\n",
        "sns.boxplot(x='x', y='y', data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWktFZLMoC99"
      },
      "outputs": [],
      "source": [
        "#@title Box Plot (Adjust Color and Plot One Candlestick)\n",
        "\n",
        "# Filter data\n",
        "var_name = data[data['x'] == 'value']\n",
        "\n",
        "# Figure size\n",
        "plt.figure(figsize=(3, 6))\n",
        "\n",
        "# Generate box plot\n",
        "sns.boxplot(x='x', y='x1', data=var_name, color='green')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scatterplot\n",
        "\n",
        "# Import library\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate scatterplot\n",
        "sns.regplot(x=data['x'], y=data['x1'], ci=None)"
      ],
      "metadata": {
        "id": "sQ83ZP5YauYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ubBUJ0ntwir"
      },
      "outputs": [],
      "source": [
        "#@title Linear Regression Plot\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Linear regression line\n",
        "sns.lmplot(x='x', y='x1', data=data)\n",
        "\n",
        "# Save plot (in current working directory)\n",
        "plt.savefig('linear_regression.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekFxylkIxzdQ"
      },
      "outputs": [],
      "source": [
        "#@title Histogram (No Parameter Adjustment)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Adjust the figure size\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Generate histogram\n",
        "sns.histplot(data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKlh7Hvo0IYq"
      },
      "outputs": [],
      "source": [
        "#@title Histogram (Binwidth and KDE)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ajust figure size\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Generate histogram\n",
        "sns.histplot(data=data['x'], binwidth=10, kde=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzSKqTtt1nVE"
      },
      "outputs": [],
      "source": [
        "#@title Histogram (Color)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Adjust figure size\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Generate histogram\n",
        "sns.histplot(data=data['x'], binwidth=4, color='red')\n",
        "\n",
        "# For a list of color names:\n",
        "# https://matplotlib.org/stable/gallery/color/named_colors.html\n",
        "# 'color' parameter: sets histogram color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnnXG_dEsW6g"
      },
      "outputs": [],
      "source": [
        "#@title Histogram with Automatic Binning and Color\n",
        "\n",
        "# Import library\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate histogram\n",
        "sns.histplot(data['x'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2g92jlMsZ78"
      },
      "outputs": [],
      "source": [
        "#@title Histogram with Automatic Binning and Custom Color Input\n",
        "\n",
        "# Import library\n",
        "import seaborn as sns\n",
        "\n",
        "# Get user input on histogram color\n",
        "custom_color = input('Type the name of a color : ')\n",
        "\n",
        "# Generate histogram\n",
        "sns.histplot(data['x'], color=custom_color, binwidth=1)\n",
        "\n",
        "# For a list of color names:\n",
        "# https://matplotlib.org/stable/gallery/color/named_colors.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnUD_BdHszn_"
      },
      "outputs": [],
      "source": [
        "#@title Histogram with Custom Binning and Custom Color\n",
        "\n",
        "# Import library\n",
        "import seaborn as sns\n",
        "\n",
        "# Get user input for color\n",
        "custom_color = input('Type the name of a color : ')\n",
        "\n",
        "# Get user input for bins\n",
        "custom_binwidth = int(input('Enter the width of the bins : '))\n",
        "\n",
        "# Generate histogram\n",
        "sns.histplot(data['x'], color=custom_color, binwidth=custom_binwidth)\n",
        "\n",
        "# For a list of color names:\n",
        "# https://matplotlib.org/stable/gallery/color/named_colors.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5t_XduBhI-h"
      },
      "outputs": [],
      "source": [
        "#@title Count Plot (Horizontal)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate horizontal bar plot\n",
        "plt.figure(figsize=(8, 15))\n",
        "sns.set_theme(style='darkgrid')\n",
        "ax = sns.countplot(\n",
        "    y='x5',\n",
        "    data=data,\n",
        "    palette='Set1',\n",
        "    hue='x5',\n",
        "    legend=False\n",
        "    )\n",
        "\n",
        "# Notes:\n",
        "# 'set_theme' style parameter options: darkgrid, whitegrid, dark, white, ticks\n",
        "# 'palette' parameter options: Set1, Set2, Set3, etc.\n",
        "# 'hue' parameter: groups data by a column name\n",
        "# 'legend' parameter: controls legend display (True/False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omrg6lKtnhKT"
      },
      "outputs": [],
      "source": [
        "#@title Bar Plot aka Count Plot (Vertical)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate vertical bar plot\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.set_theme(style='darkgrid')\n",
        "ax = sns.countplot(\n",
        "    x='x6',\n",
        "    data=data,\n",
        "    palette='Set1',\n",
        "    hue='x6',\n",
        "    legend=False\n",
        "    )\n",
        "\n",
        "# Notes:\n",
        "# 'set_theme' style parameter options: darkgrid, whitegrid, dark, white, ticks\n",
        "# 'palette' parameter options: Set1, Set2, Set3, etc.\n",
        "# 'hue' parameter: groups data by a column name\n",
        "# 'legend' parameter: controls legend display (True/False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_QohoNEkLXV"
      },
      "outputs": [],
      "source": [
        "#@title Count Plot (Customization)\n",
        "\n",
        "# Import library\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate bar plot\n",
        "ax = sns.countplot(\n",
        "    y='y',\n",
        "    data=data,\n",
        "    linewidth=2,\n",
        "    edgecolor=sns.color_palette('dark', 6)\n",
        "    )\n",
        "\n",
        "# Notes:\n",
        "# 'y': horizontal count plot orientation\n",
        "# 'linewidth': thickness of the edges around bars\n",
        "# 'edgecolor': custom edge color (e.g. Seaborn 'dark' palette, six shades)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKJVc8Pz5YGv"
      },
      "outputs": [],
      "source": [
        "#@title Bar Plot (No Parameter Adjustment)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Adjust figure size\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Generate bar plot\n",
        "sns.barplot(x='y', y='x1', data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqvHNu0-7hGr"
      },
      "outputs": [],
      "source": [
        "#@title Bar Plot (Adjust Color)\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Adjust figure size\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Generate bar plot (adjust color)\n",
        "sns.barplot(x='y', y='x1', data=data, color='orange')\n",
        "\n",
        "# For a list of color names:\n",
        "# https://matplotlib.org/stable/gallery/color/named_colors.html\n",
        "# 'color' parameter: sets histogram color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjrpLGMp8mj1"
      },
      "outputs": [],
      "source": [
        "#@title Bar plot with One Bar\n",
        "\n",
        "# Import libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter data\n",
        "filtered = data[data['x'] == 'value']\n",
        "\n",
        "# Adjust figure size\n",
        "plt.figure(figsize=(3, 6))\n",
        "\n",
        "# Generate bar plot\n",
        "sns.barplot(\n",
        "    x='x',\n",
        "    y='y',\n",
        "    data=filtered,\n",
        "    color='green',\n",
        "    err_kws={'color': 'red', 'linewidth': 5}\n",
        "    )\n",
        "\n",
        "# Display plot\n",
        "plt.show()\n",
        "\n",
        "# Notes:\n",
        "# 'x': x-axis column name (categorical variable)\n",
        "# 'y': y-axis column name (numeric variable)\n",
        "# 'err_kws': error bar color and width"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IMbC0VFPn8j"
      },
      "source": [
        "# Data Generation: Discrete and Continuous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Vk7VMDtoN5"
      },
      "outputs": [],
      "source": [
        "#@title Generating Random Data: Discrete RV (Array Edition)\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Create generator object\n",
        "rng = np.random.default_rng(seed=100)\n",
        "\n",
        "# Define bounds\n",
        "lower_bound = 1 # Inclusive lower bound\n",
        "upper_bound = 7 # Exclusive upper bound\n",
        "\n",
        "# Adjust array size\n",
        "array_size = 1\n",
        "\n",
        "# Generate random integer (example: rolling a die)\n",
        "rand_num = rng.integers(low=lower_bound, high=upper_bound, size=array_size)\n",
        "\n",
        "# Display result\n",
        "rand_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvTaz-jiuLRC"
      },
      "outputs": [],
      "source": [
        "#@title Generating Random Data: Discrete RV (Matrix Edition)\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Create generator object\n",
        "rng = np.random.default_rng(seed=100)\n",
        "\n",
        "# Define bounds\n",
        "lower_bound = 1 # Inclusive lower bound\n",
        "upper_bound = 7 # Exclusive upper bound\n",
        "\n",
        "# Adjust two-dimensional array\n",
        "matrix_size = (2, 4)\n",
        "\n",
        "# # Generate random number matrix (including upper bound)\n",
        "list_num = rng.integers(\n",
        "    low=lower_bound,\n",
        "    high=upper_bound,\n",
        "    size=matrix_size,\n",
        "    endpoint=True\n",
        "    )\n",
        "\n",
        "# Display result\n",
        "list_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqN8xk9JuZ2Q"
      },
      "outputs": [],
      "source": [
        "#@title Generating Random Data: Discrete RV (Binomial Distribution)\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Create generator object\n",
        "rng = np.random.default_rng(seed=100)\n",
        "\n",
        "# Number of trials\n",
        "num_trials = 10\n",
        "\n",
        "# Probability of success\n",
        "p_success = 0.5\n",
        "\n",
        "# Number of experiments\n",
        "num_exp = 1000\n",
        "\n",
        "# Generate sample from the binomial distribution\n",
        "sample = rng.binomial(num_trials, p_success, size=num_exp)\n",
        "\n",
        "# Display sample\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOJhTOeFuqfV"
      },
      "outputs": [],
      "source": [
        "#@title Generating Random Data: Continuous RV (Array Edition)\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Create a generator object\n",
        "rng = np.random.default_rng(seed=42)\n",
        "\n",
        "# Specify parameters\n",
        "mean = 3\n",
        "standard_deviation = 2\n",
        "sample_size = 20\n",
        "\n",
        "# Generate normal distribution sample\n",
        "sample = rng.normal(loc=mean, scale=standard_deviation, size=sample_size)\n",
        "\n",
        "# Display sample\n",
        "sample\n",
        "\n",
        "# Notes:\n",
        "# 'loc' specifies the mean\n",
        "# 'scale' specifies the standard deviation\n",
        "# 'size' specifies the number of samples\n",
        "# default values when not specified: loc=0, scale=1, size=none"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_b2OZt6vClD"
      },
      "outputs": [],
      "source": [
        "#@title Generating Random Data: Continuous RV (Matrix Edition)\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Create generator object\n",
        "rng = np.random.default_rng(seed=42)\n",
        "\n",
        "# Specify n-dimensional array of samples\n",
        "matrix_size = (2,4)\n",
        "\n",
        "# Generate sample\n",
        "sample = rng.normal(loc=mean, scale=standard_deviation, size=matrix_size)\n",
        "\n",
        "# Display sample\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePR7qtwHvLOs"
      },
      "outputs": [],
      "source": [
        "#@title Generating Random Data: Continuous RV (Multiple Means)\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Create generator object\n",
        "rng = np.random.default_rng(seed=42)\n",
        "\n",
        "# Define means (e.g., mean1, mean2)\n",
        "loc_list = [0,5]\n",
        "\n",
        "# Define standard deviations (e.g., sd1, sd2)\n",
        "scale_list = [1,2]\n",
        "\n",
        "# Define size of output sample\n",
        "row = 5\n",
        "column = 2\n",
        "\n",
        "# Generate sample from normal distributions\n",
        "sample = rng.normal(loc=loc_list, scale=scale_list, size=(row, column))\n",
        "\n",
        "# Display sample\n",
        "sample\n",
        "\n",
        "# Notes:\n",
        "# 'loc' parameter can take an array of values for multiple distributions\n",
        "# 'scale' parameter can take an array of values corresponding to 'loc'\n",
        "# 'size' parameters must match array size of 'loc' and 'scale' in a dimension,\n",
        "# e.g., in this example, the column size (2) matches the array size (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKCNkT8YPtdy"
      },
      "source": [
        "# Arithmetic Operations on DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOwgwCjvwO7y"
      },
      "outputs": [],
      "source": [
        "#@title Adding Two Columns\n",
        "\n",
        "# Add columns\n",
        "data['x'].add(data['x1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S43Dq3JQwaF4"
      },
      "outputs": [],
      "source": [
        "#@title Subtracting One Column from Another\n",
        "\n",
        "# Subrtact columns\n",
        "data['x'].subtract(data['x1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8XWY5h_wjVC"
      },
      "outputs": [],
      "source": [
        "#@title Multiplying Two Columns\n",
        "\n",
        "# Multiply columns\n",
        "data['x'].multiply(data['x1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbrwHq9Ywutl"
      },
      "outputs": [],
      "source": [
        "#@title Dividing One Column by Another\n",
        "\n",
        "# Divide columns\n",
        "data['x'].divide(data['x1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5KOr0E1wz6C"
      },
      "outputs": [],
      "source": [
        "#@title Summing All Values in Columns with Numeric Values\n",
        "\n",
        "# Sum all numeric column values\n",
        "data.sum(numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFK-BC8ow7FI"
      },
      "outputs": [],
      "source": [
        "#@title Summing All Values for a Specified Column\n",
        "\n",
        "# Sum a specific column\n",
        "data['x'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LfDT6PNw9kq"
      },
      "outputs": [],
      "source": [
        "#@title Exponentiating a Specified Column\n",
        "\n",
        "# Exponentiate a specific column\n",
        "data['x'].pow(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni6vgpHzxHmt"
      },
      "outputs": [],
      "source": [
        "#@title Exponentiating Multiple Columns\n",
        "\n",
        "# Exponentiate all values, excluding the first column and row\n",
        "data.iloc[ 1: , 1:].pow(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1M-_AqUxfIv"
      },
      "outputs": [],
      "source": [
        "#@title Calculating Roots in Multiple Columns\n",
        "\n",
        "# Square root all values, excluding the first column and row\n",
        "data.iloc[ 1: , 1:].pow(1/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upAbbMK--Dfp"
      },
      "outputs": [],
      "source": [
        "#@title Rounding One DataFrame Column\n",
        "\n",
        "# Round a column to two decimal places\n",
        "data['x'].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1gOicSi--im"
      },
      "outputs": [],
      "source": [
        "#@title Rounding the Whole DataFrame\n",
        "\n",
        "# Round all (numeric) columns to three decimal places\n",
        "data.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZQvnlXR9JRF"
      },
      "outputs": [],
      "source": [
        "#@title Performing an Operation and Adding a New DataFrame Column\n",
        "\n",
        "# Create a new column with exponentiated 'x' values\n",
        "data['x6'] = data['x'].pow(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY4sxKzEQvAZ"
      },
      "source": [
        "# Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWaDWcPj_xQ7"
      },
      "outputs": [],
      "source": [
        "#@title Generate Descriptive Statistics\n",
        "\n",
        "# Descriptive stats\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descriptive Statistics (Custom Table)\n",
        "\n",
        "# Import library\n",
        "import pandas as pd\n",
        "\n",
        "# Define groups\n",
        "group1 = data['x1'][data['x2'] == 'group1']\n",
        "group2 = data['x1'][data['x2'] == 'group2']\n",
        "\n",
        "# Print descriptive statistics\n",
        "describe = pd.DataFrame(\n",
        "    {'var_name': ['group1', 'group2'],\n",
        "    'N': [len(group1), len(group2)],\n",
        "    'M': [group1.mean(), group2.mean()],\n",
        "    'SD': [group1.std(), group2.std()]}\n",
        "    )\n",
        "print(describe)"
      ],
      "metadata": {
        "id": "EcI8jn0PktTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kVLQe_e1w05"
      },
      "outputs": [],
      "source": [
        "#@title Measures of Central Tendency\n",
        "\n",
        "# Calculate and display measures of central tendency\n",
        "print(\n",
        "    f\"\"\"\n",
        "    Mean: {data['x'].mean()}\n",
        "    Median: {data['x'].median()}\n",
        "    Mode: {data['x'].mode()}\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "# Notes:\n",
        "# The central tendency calculations automatically handle missing data.\n",
        "# If no mode exists, an empty Series will be returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gJXedGyAAf0"
      },
      "outputs": [],
      "source": [
        "#@title Mean\n",
        "\n",
        "# Mean\n",
        "data['x'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFsBERQlADjD"
      },
      "outputs": [],
      "source": [
        "#@title Median\n",
        "\n",
        "# Median\n",
        "data['x'].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnUiwxefAGbi"
      },
      "outputs": [],
      "source": [
        "#@title Mode\n",
        "\n",
        "# Mode\n",
        "data['x'].mode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxHOk95wA3TO"
      },
      "outputs": [],
      "source": [
        "#@title Minimum\n",
        "\n",
        "# Minimun value\n",
        "data['x'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1aV0YGQA_Ey"
      },
      "outputs": [],
      "source": [
        "#@title Maximum\n",
        "\n",
        "# Maximum value\n",
        "data['x'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIyQpSEQBDjR"
      },
      "outputs": [],
      "source": [
        "#@title Range\n",
        "\n",
        "# Range\n",
        "data['x'].max() - data['x'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGt4KCWMBG0k"
      },
      "outputs": [],
      "source": [
        "#@title First Quartile\n",
        "\n",
        "# First quartile\n",
        "first_quartile = data.describe()['x']['25%']\n",
        "print(first_quartile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UtAfp4gBN71"
      },
      "outputs": [],
      "source": [
        "#@title Second Quartile\n",
        "\n",
        "# Second quartile\n",
        "second_quartile = data.describe()['x']['50%']\n",
        "print(second_quartile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKap7ZpNBQlz"
      },
      "outputs": [],
      "source": [
        "#@title Third quartile\n",
        "\n",
        "# Third quartile\n",
        "third_quartile = data.describe()['x']['75%']\n",
        "print(third_quartile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBSD3P_xBYo5"
      },
      "outputs": [],
      "source": [
        "#@title Interquartile Range\n",
        "\n",
        "# Interquartile range\n",
        "iqr = data.describe()['x']['75%'] - data.describe()['x']['25%']\n",
        "print(iqr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhAQITkCBbIC"
      },
      "outputs": [],
      "source": [
        "#@title Variance\n",
        "\n",
        "# Variance\n",
        "data['x'].var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByU90B8LBdiA"
      },
      "outputs": [],
      "source": [
        "#@title Standard Deviation\n",
        "\n",
        "# Standard deviation\n",
        "data['x'].std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyL2fPd_BgDt"
      },
      "outputs": [],
      "source": [
        "#@title Measurement of Skewness for One Column\n",
        "\n",
        "# Skewness for a specific column\n",
        "data['x'].skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_0J1HUWBj7s"
      },
      "outputs": [],
      "source": [
        "#@title Measurement of Skewness for All Columns\n",
        "\n",
        "# Skewness for all columns\n",
        "data.skew(axis=0, numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Measurement of Kurtosis for One Column\n",
        "\n",
        "# Kurtosis for a specific column\n",
        "data['x'].kurtosis()"
      ],
      "metadata": {
        "id": "t398Mzg6DaIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhDWP0CbBzuI"
      },
      "outputs": [],
      "source": [
        "#@title Measurement of Kurtosis for All Columns\n",
        "\n",
        "# Kurtosis for all columns\n",
        "data.kurtosis(axis=0, numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRLVB6s8yo12"
      },
      "outputs": [],
      "source": [
        "#@title Generating a Frequency Table\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Generate frequency distribution\n",
        "unique_vals, occurrences = np.unique(data['y'], return_counts=True)\n",
        "\n",
        "# Create a dictionary object with unique values and frequencies\n",
        "freq_distribution = {\n",
        "    'Value': pd.Series(unique_vals),\n",
        "    'Frequency': pd.Series(occurrences)\n",
        "    }\n",
        "\n",
        "# Convert the dictionary object to a DataFrame\n",
        "freq_table = pd.DataFrame(freq_distribution)\n",
        "\n",
        "# Display frequency table\n",
        "freq_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQJgZLF_auon"
      },
      "outputs": [],
      "source": [
        "#@title Generating a Frequency Table with Relative Frequency\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define relative frequency percentage function\n",
        "def calculate_percentage(counts, total):\n",
        "    \"\"\"\n",
        "    Calculate the percentage for each count relative to the total.\n",
        "    Divide each count by total number of counts and multiply by 100.\n",
        "    Return the results as a list.\n",
        "    \"\"\"\n",
        "    percentages = [] # Initialize empty list\n",
        "    for each in counts: # Iterate through counts array\n",
        "        percentages.append((each / total) * 100) # Append percentage to list\n",
        "    return percentages # Return resulting percentage list\n",
        "\n",
        "# Generate frequency distribution (unique values and counts arrays)\n",
        "unique_vals, occurrences = np.unique(data['y'], return_counts=True)\n",
        "\n",
        "# Call function to calculate relative frequencies\n",
        "rel_freq = calculate_percentage(occurrences, len(data['y']))\n",
        "\n",
        "# Create a dictionary object with values, frequencies, and percentages\n",
        "freq_distribution = {\n",
        "    'Value': unique_vals,\n",
        "    'Frequency': occurrences,\n",
        "    'Percent': rel_freq\n",
        "    }\n",
        "\n",
        "# Convert the dictionary object to a DataFrame\n",
        "rel_freq_table = pd.DataFrame(freq_distribution)\n",
        "\n",
        "# Display frequency table\n",
        "rel_freq_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVK2_-iFrpCo"
      },
      "outputs": [],
      "source": [
        "#@title Calculating Intervals Around a Mean\n",
        "\n",
        "# Calculate mean\n",
        "mean = data['x'].mean()\n",
        "\n",
        "# Calculate standard deviation\n",
        "sdev = data['x'].std()\n",
        "\n",
        "# Get user input on number of standard deviations\n",
        "num_sd = int(input('Number of standard deviations from mean: '))\n",
        "\n",
        "# Display interval around mean\n",
        "(mean - num_sd * sdev, mean + num_sd * sdev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1LKC-5VdGWO"
      },
      "outputs": [],
      "source": [
        "#@title Calculating Intervals Around a Mean using `numpy` Standard Deviation\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Calculate mean\n",
        "mean = data['x'].mean()\n",
        "\n",
        "# Calculate population standard deviation\n",
        "sdev = np.std(data['x'], ddof=1)\n",
        "\n",
        "# Set to one standard deviation\n",
        "(mean - 1 * sdev, mean + 1 * sdev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHt5UAc3dGWO"
      },
      "outputs": [],
      "source": [
        "#@title Calculating Intervals Around a Mean using `numpy` and User Input\n",
        "\n",
        "# Import library\n",
        "import numpy as np\n",
        "\n",
        "# Calculate mean\n",
        "mean = data['x'].mean()\n",
        "\n",
        "# Population standard deviation\n",
        "sdev = np.std(data['x'], ddof=1)\n",
        "\n",
        "# Get user input on number of standard deviations\n",
        "num_sd = int(input('Number of standard deviations from mean: '))\n",
        "\n",
        "# Set to the number of standard deviations set by user\n",
        "(mean - num_sd * sdev, mean + num_sd * sdev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWoKhv3AOesq"
      },
      "outputs": [],
      "source": [
        "#@title Determining Population Variance\n",
        "\n",
        "# Calculate population variance (adjusted from sample variance)\n",
        "data['x'].var() * (len(data['x']) - 1) / len(data['x'])\n",
        "\n",
        "# Notes:\n",
        "# First, ensure data['x'] has no NAs before calculation.\n",
        "# The 'var()' function calculates sample variance. This is then scaled by the\n",
        "# factor (N-1)/N to adjust the sample variance for an unbiased estimate of the\n",
        "# population variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eclovlfSTJiv"
      },
      "outputs": [],
      "source": [
        "#@title Determining Population Standard Deviation\n",
        "\n",
        "# Import library\n",
        "from math import sqrt\n",
        "\n",
        "# Calculate population standard deviation (adjusted from sample variance)\n",
        "sqrt(data['x'].var() * (len(data['x']) - 1) / len(data['x']))\n",
        "\n",
        "# Notes:\n",
        "# Ensure data['x'] has no NAs before calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWD4AUWddGWP"
      },
      "outputs": [],
      "source": [
        "#@title Simulating the Impact of Outliers on Mean Calculation\n",
        "\n",
        "# Create a copy of column 'x'\n",
        "with_outlier = data['x']\n",
        "\n",
        "# Create a new single score equal to three times the mean\n",
        "new_score = data['x'].mean() * 3\n",
        "\n",
        "# Create a new single score\n",
        "new_score = pd.Series([8])\n",
        "\n",
        "# Add the outlier to the copy\n",
        "with_outlier = pd.concat([with_outlier, new_score])\n",
        "\n",
        "# Calculate mean with the outlier\n",
        "with_outlier.mean()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}